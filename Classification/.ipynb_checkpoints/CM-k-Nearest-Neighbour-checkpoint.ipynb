{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing KNN,and ROC/AUC analysis on data\n",
    "\n",
    "- #### Procedures:\n",
    "    - ##### ---------------------1.The proccess for whole features\n",
    "    - ##### 1.1.Implement a KNN classifier\n",
    "    - ##### 1.2.Train data with cross validation to calculate the avarage accuracy and choose the Best K and observe average accuracy\n",
    "    - ##### 1.3.Predict the Y_test for submission with the classifier with Best K\n",
    "    - ##### 1.4.Split train data into cross_train and cross_test to observe the accuracy,draw the ROC and calculate AUC with Best K\n",
    "    - ##### ---------------------2.The proccess for subset of features\n",
    "    - ##### 2.1..Train data with cross validation to calculate the avarage accuracy and choose the Best K and observe average accuracy\n",
    "    - ##### ---------------------3.Compare the performance of KNN with whole features and subset of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, roc_auc_score \n",
    "from collections import Counter\n",
    "from random import seed\n",
    "from random import randrange\n",
    "from sklearn import feature_selection\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ##### ---------------------1.The proccess for whole features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1:  Implement a KNN classifier\n",
    "\n",
    "\n",
    "##### First: Load classification data\n",
    "Download `X_train.csv` and `X_test.csv`,`y_train.csv` from Moodle. In X_train.csv, each row corresponds to an instance.the columns representing all of the features. The same format is used in `X_test.csv`. Load these datasets into python (numpy.loadtxt) and create an X matrix consisting of 112 columns and a Y_train as training t. Do the same for the test data so we have four objects: $\\mathbf{X}_{train}$, $\\mathbf{X}_{test}$, and $\\mathbf{Y}_{train}$.and normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 113)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.loadtxt('X_train.csv', delimiter=',', skiprows=1)\n",
    "X_test = np.loadtxt('X_test.csv', delimiter=',', skiprows=1)\n",
    "Y_train = np.loadtxt('y_train.csv', delimiter=',', skiprows=1)[:,1][:,None]\n",
    "\n",
    "# Make an instance of the Model\n",
    "\n",
    "feature_scaler = StandardScaler()\n",
    "X_train = feature_scaler.fit_transform(X_train)\n",
    "X_test = feature_scaler.transform(X_test)\n",
    "\n",
    "\n",
    "X_Y_train = np.column_stack((X_train,Y_train))\n",
    "print(X_Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Second: write k-fold cross validation data spliter to split train data into k folds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 100, 113)\n"
     ]
    }
   ],
   "source": [
    "# Split a dataset into k folds\n",
    "def cross_validation_split(data, folds):\n",
    "    data_split = list()\n",
    "    data_copy = list(data)\n",
    "    fold_size = int(len(data) / folds)\n",
    "    for i in range(folds):\n",
    "        fold_list = list()\n",
    "        while len(fold_list) < fold_size:\n",
    "            index = randrange(len(data_copy))\n",
    "            fold_list.append(data_copy.pop(index))\n",
    "        data_split.append(fold_list)\n",
    "    return data_split\n",
    " \n",
    "# test cross validation split\n",
    "seed(1)\n",
    "fold = 2\n",
    "splited_data = np.array(cross_validation_split(X_Y_train,fold))\n",
    "print(splited_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Third: Write a KNN function for a single test example (a row)\n",
    "Implement a KNN function that takes a single test example and a value of K and returns a classification. the function will find the K closest (see below) training points to the test point and return the majority class\n",
    "amongst these training points.\n",
    "\n",
    "The distance between a test point and the ith row is given by:\n",
    "\n",
    "`sq_difference = (test_row - X_train[i,:])**2\n",
    "distance = np.sqrt(sq_difference.sum())`\n",
    "\n",
    "where test_row is a row of $\\mathbf{X}_{test}$.\n",
    "The first line creates a new vector which holds the squared difference of the two pairs of values. The second line takes the sum of these differences and then takes the square root. This is computing the Euclidean distance. Other distance metrics could also be used.\n",
    "\n",
    "the predicted score and the predicted class will be returned as dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_classifier(trainX, traint, test_data, K):\n",
    "    # computing distances between the testing data(one row)to all training data\n",
    "    distances = np.sqrt(((trainX - test_data)**2).sum(axis=1)) \n",
    "    # zip the train data distance and the class them below to dy \n",
    "    dy = zip(distances, traint) \n",
    "    # sort the dy bt distance\n",
    "    dy = sorted(dy, key = lambda x: x[0]) \n",
    "    # select K instances of neareast neighbours\n",
    "    k_selected_neighbor = np.asarray(dy[:K]) \n",
    "    classes, counts = np.unique(k_selected_neighbor[:,1], return_counts=True)\n",
    "    prediction = {}\n",
    "    # assign the class of training data to the testing data with the highest ammount\n",
    "    prediction[\"predicted_class\"] = classes[counts.argmax()]\n",
    "    # calculate the prediction score for testing data \n",
    "    if ( len(classes) == 1 and classes[counts.argmax()] == 2.0):\n",
    "        prediction[\"predicted_score\"] = np.hstack( (1.0- (1.0*counts/sum(counts)), 1.0*counts/sum(counts) ) )\n",
    "    elif ( len(classes) == 1 and classes[counts.argmax()] == 1.0):\n",
    "        prediction[\"predicted_score\"] = np.hstack( ( 1.0*counts/sum(counts), 1.0- (1.0*counts/sum(counts)) ) )\n",
    "    else:\n",
    "        prediction[\"predicted_score\"] = 1.0*counts/sum(counts)\n",
    "    return(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2.Train data with cross validation to calculate the avarage accuracy and choose the Best K and observe average accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.82, 7), (0.9, 0)]\n",
      "The average accuracy : 0.86\n",
      "The average k : 3.5\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i in range(fold):\n",
    "    fold_X_train = splited_data[i,:,:-1]\n",
    "    fold_Y_train = splited_data[i,:,-1]\n",
    "    cross_fold_X_train, cross_fold_X_test, cross_fold_Y_train, cross_fold_Y_test = train_test_split(fold_X_train,fold_Y_train, test_size=0.5,random_state=1234)\n",
    "    ctrain = Counter(cross_fold_Y_train.flatten())\n",
    "    \n",
    "    Kvals = np.arange(1,100,1)\n",
    "    accuracy = []\n",
    "\n",
    "    for k in Kvals:\n",
    "        correct = 0\n",
    "        for i,row in enumerate(cross_fold_X_test):\n",
    "            c = knn_classifier(cross_fold_X_train,cross_fold_Y_train,row,K=k)[\"predicted_class\"]\n",
    "            if c == cross_fold_Y_test[i]:\n",
    "                correct += 1\n",
    "        accuracy.append(1.0*correct / (1.0*len(cross_fold_X_test)))\n",
    "    results.append((max(accuracy),np.array(accuracy).argmax()))\n",
    "print(results)\n",
    "temp = 0\n",
    "k = 0\n",
    "for (i,j) in results:\n",
    "    temp += i\n",
    "    k += j\n",
    "print(\"The average accuracy :\",temp/len(results))\n",
    "print(\"The average k :\",k/len(results))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.3.Predict the Y_test for submission with the classifier with Best K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction = []\n",
    "for i in range(len(X_test)):\n",
    "    c = knn_classifier(X_train,Y_train,X_test[i,:],K=4)\n",
    "    y_prediction.append(c[\"predicted_class\"])\n",
    "y_prediction = np.array(y_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.   2.]\n",
      " [  1.   2.]\n",
      " [  2.   2.]\n",
      " ...\n",
      " [795.   1.]\n",
      " [796.   2.]\n",
      " [797.   2.]]\n"
     ]
    }
   ],
   "source": [
    "test_header = \"Id,EpiOrStroma\"\n",
    "n_points = X_test.shape[0]\n",
    "y_pred_pp = np.ones((n_points, 2))\n",
    "y_pred_pp[:, 0] = range(n_points)\n",
    "y_pred_pp[:, 1] = y_prediction[:,0]\n",
    "print(y_pred_pp)\n",
    "\n",
    "np.savetxt('my_submission_k_nearest_neighbour_cl.csv', y_pred_pp, fmt='%d', delimiter=\",\",header=test_header, comments=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4.Split train data into cross_train and cross_test again to observe the accuracy for comfirmation,draw the ROC and calculate AUC with Best K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_X_train, cross_X_test, cross_Y_train, cross_Y_test = train_test_split(X_train,Y_train, test_size=0.5,random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_knn = np.zeros((100, 3))\n",
    "for j,tx in enumerate(cross_X_test):\n",
    "    knn_results = knn_classifier(cross_X_train, cross_Y_train, tx, K = 4)\n",
    "    predictions_knn[j, 0] = knn_results['predicted_class']\n",
    "    predictions_knn[j, 1:] = knn_results['predicted_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### First: test the cross_X_test 's ROC curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Sensitivity or True Positive Rate')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAkmElEQVR4nO3de5wU9Znv8c9XwLCI4gV0VVDUIAZvCHiLbrwlWeOJYqInXpKo0YSYE+Nt4x49Jq7rJmfjqskmG42SjdHNRU10NaxijPGeibceUQREFhUETDZgEEVW5PLsH78aaMaZnhpmqnu6+/t+vfrVVdXV1U9NQz1dv6fq91NEYGZmzWuTWgdgZma15URgZtbknAjMzJqcE4GZWZNzIjAza3L9ax1Adw0dOjRGjhxZ6zDMzOpKa2vrkogY1tFrdZcIRo4cSalUqnUYZmZ1RdL8zl5z05CZWZNzIjAza3JOBGZmTc6JwMysyTkRmJk1ucISgaQbJf1J0oxOXpek70maK2m6pHFFxWJmZp0r8ozgJuDoCq9/DBiVPSYBPygwFjMz60Rh9xFExKOSRlZYZSLwb5H6wX5C0paSto+IPxQVk5lZr4mANWtg9WpYtSo9ip4+9ljYf/9e35Va3lC2I7CgbH5htuw9iUDSJNJZAzvttFNVgjOzXrJmTXUOkrWYrrYddmi4RJBbREwGJgNMmDDBI+lY46n2L8tqTa9enX45V1P//jBgwPrnvNMDB3Zv/WpP9+sHUjF/skK2ms8iYETZ/PBsmVnH1q7tGwe3IqarfbDs12/jDkoDB/adA2NH0wUeLBtZLRPBFOAcSbcCBwLLXB8w3ngDZs5Mjxkz1j8vWZISQTX167dxB6XNNus7B8aOpvv398HSNlBYIpB0C3A4MFTSQuDvgAEAEXE9MBU4BpgLrAA+V1Qs1gctXw4vvJAO8uUH/EVlJ4WDB8OYMfDxj8P221f3gNm/P2zi22ysORR51dApXbwewJeL+nzrI955B2bP3vBgP3MmvPLK+nUGDoQPfACOPBL23BP22is977STD8ZmVVAXxWKrA6tWwZw57z3gz527vklnwAAYPRoOOADOPHP9AX/XXVMzjJnVhBOBdc+aNfDSS+9tw3/xxVT4hPQrftSodKA/+eT1v/JHjUrJwMz6FCcC69jatTB//nsP+LNnp+aeNrvskg7yxx23/oA/enRq7jGzuuBE0Owi4LXX3tukM3MmvP32+vWGD08H+aOOWt+k84EPpIKumdU1J4JmFQGTJ8Oll8Lrr69fvt126UB/1lnrD/h77glDhtQuVjMrlBNBM1qyBD7/efjVr+CII+CEE9Yf9IcOrXV0ZlZlTgTN5re/hdNOS2cB3/42nHeeL9E0a3I+AjSLlSvhq1+Fj3wEttwSnnwSLrjAScDMfEbQFGbPhlNPhWnT4EtfgquvhkGDah2VmfUR/jnYyCLghhtg3Dh49dVUE7juOicBM9uAE0GjWrIEPvEJOPtsOPRQeP75dK2/mVk7TgSN6Le/hX32gXvvhWuugV//OnXaZmbWASeCRvLuu3DRRakgPGRIKghfeKELwmZWkYvFjcIFYTPbSP6pWO9cEDazHnIiqGevvw6f/KQLwmbWI10mAiWfkXRZNr+TpAOKD80qaisIT53qgrCZ9UieM4LrgIOBthHH3gKuLSwiq6y8ILzFFi4Im1mP5SkWHxgR4yRNA4iIpZI2LTgu60h5Qfjss9OZgGsBZtZDeX5GrpLUDwgAScOAtYVGZRtq6zK6rSB8113wgx84CZhZr8iTCL4H3AlsK+mbwO+Afyw0KluvrSD8xS+uLwhPnFjrqMysgXTZNBQRP5PUChwFCDg+Il4oPDKDBx5IXUYvXpyagc4/37UAM+t1XSYCST+JiM8CsztYZkV491342tfSTWGjR8M998DYsbWOyswaVJ5i8Z7lM1m9YHwx4RizZ8OnPw3PPOOCsJlVRaftDJIukfQWsI+kNyW9lc3/CfhV1SJsFuUF4fnzXRA2s6rpNBFExD9GxObAVRGxRURsnj22iYhLqhhj43v99TRu8Be/CIccAtOnuyBsZlWTp1h8iaStgFHAwLLljxYZWNMoLwhffbWHjzSzqstTLP48cB4wHHgWOAh4HDiy0MgaXfuC8N13w3771ToqM2tCeX56ngfsD8yPiCOA/YA3igyq4b34Ihx8MFx1FUyaBK2tTgJmVjN5rhp6JyLekYSk90XEbEmjC4+skR17LPz5z3DnnXD88bWOxsyaXJ5EsFDSlsBdwP2SlgLziwyqoS1YAP/5n/Dd7zoJmFmf0GXTUER8IiLeiIjLga8DPwJyXdIi6WhJL0qaK+niDl7fSdJDkqZJmi7pmO7uQN1paUnPhxxS2zjMzDLdujwlIh4B3gGmdrVuduPZtcDHgDHAKZLGtFvta8AvImI/4GRSl9eNraUFNtsM9t231pGYmQGVbyg7UtIcScsl/VTS3pJKpA7nfpBj2wcAcyPi5Yh4F7iV955JBLBFNj0EeK37u1BnWlrgwAOhv4eLNrO+odIZwTXAJGAb4HbSJaM3RcT4iPj3HNveEVhQNr8wW1bucuAzkhaSzjK+0tGGJE2SVJJUWrx4cY6P7qPeeguee87NQmbWp1RKBBERD0fEyoi4C1gUEd/v5c8/hZRchgPHAD+R9J6YImJyREyIiAnDhg3r5RCq6MknYe1aJwIz61MqtU9sKemT5euWz+c4K1gEjCibH54tK3cWcHS2vcclDQSGkvozajwtLSDBQQfVOhIzs3UqJYJHgGPL5h8tmw+gq0TwNDBK0i6kBHAycGq7dV4ljXNwk6QPkLqwqOO2ny787new994wZEitIzEzW6fTRBARn+vJhiNitaRzgPuAfsCNETFT0hVAKSKmAH8D/FDSBaTkckZERE8+t89avRqeeAI+62EczKxvKfTSlYiYSrtLTSPisrLpWUBzNJg//zwsX+76gJn1Oe7mslp8I5mZ9VFOBNXS0gI77gg771zrSMzMNtBlIpA0SNLXJf0wmx8l6ePFh9ZgWlrS2YBU60jMzDaQ54zgx8BK4OBsfhHwjcIiakQLFqSHm4XMrA/Kkwh2i4h/AlYBRMQKwD9ru8P1ATPrw/Ikgncl/QXp8k4k7UY6Q7C83NGcmfVheS4fvRz4NTBC0s9Il3ueUWBMjccdzZlZH5Zn8PrfSGoljVUs4LyIWFJ4ZI2iraO5Sy+tdSRmZh3KM3j9fwA/B6ZExNvFh9Rg3NGcmfVxeWoEVwN/BcySdLukE7PO4SwPdzRnZn1cnqahR4BHshHHjgS+ANzI+gFlrJKWFnc0Z2Z9Wq47i7Orhk4Azgb2B24uMqiGsWZN6mjOzUJm1oflqRH8gjTs5K+B7wOPRMTaogNrCM8/n4rFTgRm1ofluZ7xR8ApEbGm6GAajm8kM7M60GkikHRkRDwIbAZMVLs+cnKOW9zcWlpghx3c0ZyZ9WmVzggOAx5kw1HK2uQZoczc0ZyZ1YFKI5T9XTZ5RUS8Uv5aNvykVbJwIbz6Klx4Ya0jMTOrKM9VQ3d0sOz23g6k4bg+YGZ1olKNYA9gT2CIpE+WvbQFaZB5q6SlBQYNckdzZtbnVaoRjAY+DmzJhnWCt0g3lVklbR3NDRhQ60jMzCqqVCP4FfArSQdHxONVjKn+LV+eOpq75JJaR2Jm1qVKTUN/mw1Ic6qkU9q/HhHnFhpZPXvyyXRXsesDZlYHKjUNvZA9l6oRSENp62ju4IO7XtfMrMYqNQ39R/a8rl8hSZsAgyPizSrEVr9aWmCvvdzRnJnVhS4vH5X0c0lbSNoMmEHqjvqi4kOrU2vWwOOPu1nIzOpGnvsIxmRnAMcD9wK7AJ8tMqi6NmOGO5ozs7qSJxEMkDSAlAimRMQqsoHsrQO+kczM6kyeRHADMI/U+dyjknYGXCPoTEsLbL89jBxZ60jMzHLJM0LZ94DvlS2aL+mI4kKqc+5ozszqTJ5i8RBJ35ZUyh7XkM4OrL1Fi2D+fDcLmVldydM0dCOpW4lPZY83gR/n2bikoyW9KGmupIs7WedTkmZJminp53kD75NcHzCzOpRnhLLdIuKEsvm/l/RsV2/KBru/FvgIsBB4WtKUiJhVts4o4BLgkIhYKmnbbkXf17R1NDd2bK0jMTPLLc8ZwX9LOrRtRtIhwH/neN8BwNyIeDki3gVuBSa2W+cLwLURsRQgIv6UL+w+qqUFDjjAHc2ZWV3JkwjOBq6VNE/SPNIA9l/M8b4dgQVl8wuzZeV2B3aX1CLpCUlHd7QhSZPaahSLFy/O8dE1sHw5PPusm4XMrO5UbBqSNBZ4P3AysAigl7uX6A+MAg4HhpMuT907It4oXykiJgOTASZMmNA372F46il3NGdmdanTMwJJlwG/AE4A7gFO6mYSWASMKJsfni0rt5DsJrVsOMw5pMRQf9zRnJnVqUpNQycBYyPiFGB/YFI3t/00MErSLpI2JZ1VTGm3zl2kswEkDSU1Fb3czc/pG1paYM89Ycstax2JmVm3VEoEKyNiBUBEvN7Fuu8REauBc4D7SF1a/yIiZkq6QtJx2Wr3Aa9LmgU8BFyUfVZ9cUdzZlbHKtUIdpXU9gtewG5l80TEcR2/bb2ImApMbbfssrLpAC7MHvVr5kx4800nAjOrS5USQftLPa8uMpC61nYj2aGHVl7PzKwPqjQwzSPVDKSuuaM5M6tj3Wr3t064ozkzq2NOBD312mswb57rA2ZWt3InAkmDigykbrmjOTOrc3m6of5gdnnn7Gx+X0nXFR5ZvXBHc2ZW5/KcEXwH+GvgdYCIeA74UJFB1RV3NGdmdS5X01BELGi3aE0BsdSft9+GadPcLGRmdS3PeAQLJH0QiGwQ+/NIdwqbO5ozswaQtxvqL5O6kF4EjM3mzR3NmVkDyDN4/RLg01WIpf78/vcwZow7mjOzutZlIpD0Y+A9YwBExJmFRFQvIqBUgmOPrXUkZmY9kqdGcHfZ9EDgE8BrxYRTRxYsgMWLYfz4WkdiZtYjeZqG7iifl3QL8LvCIqoXpVJ6njChtnGYmfXQxnQxMQrYtrcDqTulEvTvD/vsU+tIzMx6JE+N4C02rBH8Efi/hUVUL0ol2HtvGDiw1pGYmfVIV4PXC9gzIl6tUjz1oa1QfOKJtY7EzKzHKjYNZSOI3VOlWOrHvHmwdKnrA2bWEPLUCJ6RtH/hkdQTF4rNrIF0mggknZNNHgg8LuklSdMlPS9penXC66NKJdh0U9hrr1pHYmbWY5VqBGcC3yf1PGrlSiXYd9+UDMzM6lye+wjmVyOQurF2LbS2wqmn1joSM7NeUSkR7CPpzQ6Wi1RH3qKgmPq2l16CZct8R7GZNYxKieD5iNivapHUCxeKzazBePD67iqV0k1kY8bUOhIzs15RKRH8smpR1JNSKY1P7KEpzaxBdJoIIuL/VzOQurB2LTzzjJuFzKyhuGmoO+bMgeXLnQjMrKFUTASSNpH0qWoF0+e5UGxmDairvobWAn9bpVj6vlIJBg2CPfaodSRmZr0mT9PQbyV9VdIISVu3PQqPrC8qlWDcOOjXr9aRmJn1mjyJ4CTgy8CjQGv2KOXZuKSjJb0oaa6kiyusd4KkkNR321xWr4Zp03wjmZk1nDxdTOyyMRuW1A+4FvgIsBB4WtKUiJjVbr3NgfOAJzfmc6pm9mxYscL1ATNrOF2eEUgaIOlcSbdnj3Mk5bmI/gBgbkS8HBHvArcCEztY7x+AK4F3uhV5tblQbGYNKk/T0A+A8cB12WN8tqwrOwILyuYXZsvWkTQOGBERFQe/kTRJUklSafHixTk+ugClEgweDLvvXpvPNzMrSJdNQ8D+EbFv2fyDkp7r6QdL2gT4NnBGV+tGxGRgMsCECROii9WLUSql+sAmvvXCzBpLnqPaGkm7tc1I2hVYk+N9i4ARZfPDs2VtNgf2Ah6WNA84CJjSJwvGq1bBc8+5WcjMGlKeM4KLgIckvUzqgnpn4HM53vc0MErSLqQEcDKwrhP/iFgGDG2bl/Qw8NWIyHVFUlXNmgXvvONEYGYNKc9VQw9IGgWMzha9GBErc7xvdTbc5X1AP+DGiJgp6QqgFBFTehJ4VblQbGYNLM8ZAdmBv9vjFEfEVGBqu2WXdbLu4d3dftWUSjBkCOy2W9frmpnVGVc+8yiV0tmAVOtIzMx6nRNBV1auTIVi31FsZg0qzw1l/y7pf2WXezafGTPSVUOuD5hZg8pzcL+OdLXPf0r6lqTRXb2hobhQbGYNrstEEBG/jYhPA+OAeaTeSH8v6XM5u5qob6USbL01jBxZ60jMzAqRq7lH0jakO4A/D0wDvktKDPcXFllf4UKxmTW4PDWCO4HHgEHAsRFxXETcFhFfAQYXHWBNvfNOqhG4WcjMGlie+wh+mN0PsI6k90XEyoho7CPk9OlpHAInAjNrYHmahr7RwbLHezuQPsmFYjNrAp2eEUj6S1K30X8haT9SP0MAW5CaiRpfqQTbbgvDh9c6EjOzwlRqGvprUoF4OKm76DZvAf+vwJj6jraup10oNrMG1mkiiIibgZslnRARd1Qxpr5hxQqYOROOP77WkZiZFapS09BnIuKnwEhJF7Z/PSK+3cHbGsezz8Lata4PmFnDq9Q0tFn23NiXiHbGhWIzaxKVmoZuyCavi4gaDRRcQ6USbL897LBDrSMxMytUnstHWyT9RtJZkrYqPKK+orXVZwNm1hTy9DW0O/A1YE+gVdLdkj5TeGS1tHw5vPCCE4GZNYVcfQ1FxFMRcSFwAPBn4OZCo6q1adMgwonAzJpCnr6GtpB0uqR7gd8DfyAlhMbVVij2YDRm1gTy9DX0HHAXcEVENE/XEiNGwHbb1ToSM7PC5UkEu0ZEFB5JX9J2R7GZWROodEPZP0fE+cAUSe9JBBFxXJGB1cyyZTBnDpx2Wq0jMTOrikpnBD/Jnq+uRiB9xjPPpGcXis2sSVS6oaw1mxwbEd8tf03SecAjRQZWMy4Um1mTyXP56OkdLDujl+PoO0qlND7x0KG1jsTMrCoq1QhOAU4FdpE0peylzUn3EjQm31FsZk2mUo2g7Z6BocA1ZcvfAqYXGVTNLF0KL70EX/hCrSMxM6uaSjWC+cB84ODqhVNjrVlZxGcEZtZEKjUN/S4iDpX0FlB++aiAiIgtCo+u2toKxePG1TYOM7MqqnRGcGj2vHn1wqmxUgl22w22ap5OVs3M8vQ1tJuk92XTh0s6V9KWeTYu6WhJL0qaK+niDl6/UNIsSdMlPSBp527vQW8qldwsZGZNJ8/lo3cAayS9H5gMjAB+3tWbJPUDrgU+BowBTpE0pt1q04AJEbEPcDvwT92IvXctXgzz5zsRmFnTyZMI1kbEauATwL9ExEXA9jnedwAwNyJejoh3gVuBieUrRMRDEbEim30CGJ4/9F7mQrGZNak8iWBVdk/B6cDd2bIBOd63I7CgbH5htqwzZwH3dvSCpEmSSpJKixcXNGqmC8Vm1qTyJILPkS4h/WZEvCJpF9b3Q9QrshHPJgBXdfR6REyOiAkRMWHYsGG9+dHrtbbC6NGwReNdDGVmVkmX3VBHxCzg3LL5V4Arc2x7Eame0GZ4tmwDkj4MXAocFhErc2y3GKUSHHZYzT7ezKxW8lw1dIik+yXNkfSypFckvZxj208DoyTtImlT4GSgvKsKJO0H3AAcFxF/2pgd6BV//CMsXOj6gJk1pTwD0/wIuABoBdbk3XBErJZ0DnAf0A+4MSJmSroCKEXEFFJT0GDgl5IAXq3JOAcuFJtZE8uTCJZFRIdF3K5ExFRgartll5VNf3hjttvrSiXYZBMYO7bWkZiZVV2eRPCQpKuAfwfWteFHxDOFRVVtpRLssQcMHlzrSMzMqi5PIjgwey5vNwngyN4PpwYiUiL46EdrHYmZWU3kuWroiGoEUjOvvZaKxa4PmFmTynPV0HaSfiTp3mx+jKSzig+tStpuJHMiMLMmleeGsptIV/7skM3PAc4vKJ7qK5WgXz/Yd99aR2JmVhN5EsHQiPgFsBbSZaF04zLSPq+1FfbcEwYNqnUkZmY1kScRvC1pG7LBaSQdBCwrNKpqaSsUu1nIzJpYnquGLiTdEbybpBZgGHBioVFVy4IFqftpJwIza2J5rhp6RtJhwGjSMJUvRsSqwiOrBheKzcw6bxqStL+kv4R1dYHxwDeBayRtXaX4ilUqQf/+sPfetY7EzKxmKtUIbgDeBZD0IeBbwL+R6gOTiw+tCkqllAQGDqx1JGZmNVMpEfSLiD9n0ycBkyPijoj4OvD+4kMrmAvFZmZAF4lAUlsN4SjgwbLX8hSZ+7ZXXoGlS50IzKzpVTqg3wI8ImkJ8N/AYwDZIPb1f/moC8VmZkCFRBAR35T0AGmg+t9ERGQvbQJ8pRrBFaq1FTbdFPbaq9aRmJnVVMUmnoh4ooNlc4oLp4pKpdStxKab1joSM7OaynNnceNZuzadEbhZyMysSRPBSy/BsmVOBGZmNGsicKHYzGyd5k0EAwfCmDG1jsTMrOaaNxGMHZu6lzAza3LNlwjWrIFnnnGzkJlZpvkSwZw5sHy5E4GZWab5EoELxWZmG2i+RNDamoal3GOPWkdiZtYnNF8iKJVg3Lg0YL2ZmTVZIli9GqZNc7OQmVmZ5koEs2fDihVOBGZmZZorEbQVisePr20cZmZ9SPMlgsGDYffdax2JmVmf0XyJYPx42KS5dtvMrJJCj4iSjpb0oqS5ki7u4PX3Sbote/1JSSMLC2bVKnj2WdcHzMzaKSwRSOoHXAt8DBgDnCKpfS9vZwFLI+L9wHeAK4uKh5kzYeVKJwIzs3aKPCM4AJgbES9HxLvArcDEdutMBG7Opm8HjpKkQqJpbU3PTgRmZhsoMhHsCCwom1+YLetwnYhYDSwDtmm/IUmTJJUklRYvXrxx0QwdChMnwm67bdz7zcwaVF1UTSNickRMiIgJw4YN27iNTJwId90FBZ1wmJnVqyITwSJgRNn88GxZh+tI6g8MAV4vMCYzM2unyETwNDBK0i6SNgVOBqa0W2cKcHo2fSLwYEREgTGZmVk7hQ3RFRGrJZ0D3Af0A26MiJmSrgBKETEF+BHwE0lzgT+TkoWZmVVRoWM1RsRUYGq7ZZeVTb8D/O8iYzAzs8rqolhsZmbFcSIwM2tyTgRmZk3OicDMrMmp3q7WlLQYmL+Rbx8KLOnFcOqB97k5eJ+bQ0/2eeeI6PCO3LpLBD0hqRQRTdXZkPe5OXifm0NR++ymITOzJudEYGbW5JotEUyudQA14H1uDt7n5lDIPjdVjcDMzN6r2c4IzMysHScCM7Mm15CJQNLRkl6UNFfSxR28/j5Jt2WvPylpZA3C7FU59vlCSbMkTZf0gKSdaxFnb+pqn8vWO0FSSKr7Sw3z7LOkT2Xf9UxJP692jL0tx7/tnSQ9JGla9u/7mFrE2Vsk3SjpT5JmdPK6JH0v+3tMlzSuxx8aEQ31IHV5/RKwK7Ap8Bwwpt06/we4Pps+Gbit1nFXYZ+PAAZl019qhn3O1tsceBR4AphQ67ir8D2PAqYBW2Xz29Y67irs82TgS9n0GGBerePu4T5/CBgHzOjk9WOAewEBBwFP9vQzG/GM4ABgbkS8HBHvArcCE9utMxG4OZu+HThKqusxLLvc54h4KCJWZLNPkEaMq2d5vmeAfwCuBN6pZnAFybPPXwCujYilABHxpyrH2Nvy7HMAW2TTQ4DXqhhfr4uIR0njs3RmIvBvkTwBbClp+558ZiMmgh2BBWXzC7NlHa4TEauBZcA2VYmuGHn2udxZpF8U9azLfc5OmUdExD3VDKxAeb7n3YHdJbVIekLS0VWLrhh59vly4DOSFpLGP/lKdUKrme7+f+9SoQPTWN8j6TPABOCwWsdSJEmbAN8GzqhxKNXWn9Q8dDjprO9RSXtHxBu1DKpgpwA3RcQ1kg4mjXq4V0SsrXVg9aIRzwgWASPK5odnyzpcR1J/0unk61WJrhh59hlJHwYuBY6LiJVViq0oXe3z5sBewMOS5pHaUqfUecE4z/e8EJgSEasi4hVgDikx1Ks8+3wW8AuAiHgcGEjqnK1R5fr/3h2NmAieBkZJ2kXSpqRi8JR260wBTs+mTwQejKwKU6e63GdJ+wE3kJJAvbcbQxf7HBHLImJoRIyMiJGkushxEVGqTbi9Is+/7btIZwNIGkpqKnq5ijH2tjz7/CpwFICkD5ASweKqRlldU4DTsquHDgKWRcQferLBhmsaiojVks4B7iNdcXBjRMyUdAVQiogpwI9Ip49zSUWZk2sXcc/l3OergMHAL7O6+KsRcVzNgu6hnPvcUHLu833ARyXNAtYAF0VE3Z7t5tznvwF+KOkCUuH4jHr+YSfpFlIyH5rVPf4OGAAQEdeT6iDHAHOBFcDnevyZdfz3MjOzXtCITUNmZtYNTgRmZk3OicDMrMk5EZiZNTknAjOzJudE0KS66uGwbL1Ls14sp0t6VtKBvRzHVElbZtPnSnpB0s8kHVepR9Fs/d9nzyMlndqbceUhaZ6k57O/y7OSPtjFuj26yUnS5ZIWZZ81Q1K3L/+VdEV2YyGSzpc0qOy1dd9FD+Ns+7tMl/SIuujptlbfn63ny0eblKQPActJnVft1ck6B5O6aTg8IlZmB7JNI6KQTr0kzQY+HBELu/m+w4GvRsTHi4gr+4z+Wb9U5cvmkXo0XZLj/bnXrbCNy4HlEXF1duPUY6TeRTeqK4XeiKmr7Ur6e2CHiPhChfUPp+DvzyrzGUGTytHDIcD2wJK27igiYklbEsh+9f1T9svvKUnvz5YPk3SHpKezxyHZ8sGSflz2S/GEsu0MlXQ9qavheyVdIOkMSd/P1tlO0p2SnsseH8yWL8/i/BbwV9kv5QskPSppbNtOSPqdpH0728nsDs2rsl/Zz0s6KVt+uKTHJE0BZuX5u0q6S1JrdhY1qYPXN5N0T7YfM8o+a3z267lV0n3qojfJiHgBWE266eiULO4Zkq7MttdP0k1l+3RBtvwmSSdKOhfYAXhI0kPZa23fxbckfbks5sslfTWbvij7XqdnB/muPE7WIVr2y/8xSc9kj7YzqPbfX7/s+2j7nC/m+BzriWr2s+1H33oAI+mkz/Ps9cHAs6T+aq4DDit7bR5waTZ9GnB3Nv1z4NBseifghWz6SuCfy96/Vdl2hnYwfQbw/Wz6NuD8bLofMCSbXp49H972+dn86W2fRepiodTF3+EE4P5s29uRuizYPtvu28AunbxvHvB89jd6Mlu2dfb8F8AMYJvyfcs+64dl2xhCumv098CwbNlJpDto23/e5aRfzgAHkrpb3jGLdxipp4AHgeOB8cD9Ze/dMnu+CTix/d+7XYz7AY+ULZ9F6tvmo6S+/0X6EXk38KFO/i5t3+M/A5Oy6UHAwGx6VNv30sH3Nwn4Wjb9PqDU2XfgR+88Gq6LCes9EbFc0njgr0gD29wm6eKIuClb5Zay5+9k0x8Gxmj98A5bSBqcLV/XlUdk/eXndCQp2RARa0jdhlfyS+Drki4CziQd/Co5FLgl2/Z/SXoE2B94E3gqUudtnTkiNmxaOVfSJ7LpEaQDXnkXD88D12S/3O+OiMck7UXqIO/+7O/WD+is75gLlHqQfYuUMCYAD0fEYgBJPyMNbPIPwK6S/gW4B/hNF3+DdSJimqRtJe1ASjBLI2KBpPNIyWBaturgbP8e7WAzD0namtT8+PVs2QDg+9nZ2hpSku7IR4F9JJ2YzQ/JPqfS92A94ERg60gaAfxHNnt9RFyfHRwfJvXi+Tzp1/ZN2TrlBaa26U2AgyJig4FgVMVxfyJihaT7SQN4fIr063hjvZ13xayt+8PAwVkMD5M6QCuPbY7SOAnHAN+Q9ABwJzAzIg7O8THfiYiryz6zo8F4iIilWXPYXwNnk/4OZ+bdF1IyPRH4S9IZGaQzgX+MiBtyvP8I4A3gZ8DfAxcCFwD/BexL+nfS2WBBAr4SEfd1I17rAdcIbJ2IWBARY7PH9ZJGSyrvwngsML9s/qSy58ez6d9QNjBIWVv9/UB5u/NW3QjtAdLwmm1t30Pavf4Wqdvpcv8KfA94OsfZx2PASdm2h5F+UT/VjfjaDCH9el4haQ9S19cbyH5lr4iIn5I6AhwHvAgMUyrOI2mApD1zfuZTwGFZ234/Ut/8jygV9jeJiDuAr2Wf015Hf7c2t5HO4E4kJQVIHb+dmZ3hIWlHSdt2Flik4vr5pJ4ytyb9ff4Qqbj9WdKZT0dx3Ad8SdKA7HN2l7RZhb+B9ZATQZNS6uHwcWC0pIWSzupgtcHAzcoGvSeNB3t52etbZcvPI/3aAzgXmJAV+WaRfo0CfCNbf4ak50i/GPM6DzgiOyNpzeIoNx1YkxVgLwCIiFZS086Pc2z/zmwbz5Ha2P82Iv7Yjfja/BroL+kFUgH0iQ7W2Rt4StKzpF4lvxFpCMYTgSuzv82zQKeXopaL1P3wxcBDWfytEfErUu3g4exzfgpc0sHbJwO/bisWt9vuTNLBeVH2GUTEb0g1oMez7+J2Ok8k5fHdQvoRcB1weraPe7D+bKv99/evpLrEM0qXN9+AWy8K5ctHbaOooEsPe0v2y/thYI/wSFVmFfmMwBqOpNOAJ0lXNTkJmHXBZwRmZk3OZwRmZk3OicDMrMk5EZiZNTknAjOzJudEYGbW5P4HrK01wVORxR0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr_knn, tpr_knn, th_knn = roc_curve(cross_Y_test-1, predictions_knn[:,2])\n",
    "plt.plot(fpr_knn, tpr_knn, \"r\")\n",
    "plt.xlabel(\"1-Specificity  or False Positive Rate\")\n",
    "plt.ylabel(\"Sensitivity or True Positive Rate\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### second:  Compute the AUC for KNN classifier \n",
    "\n",
    "AUCs range between 0.5 and 1. Higher AUC indicates better classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9107142857142858\n"
     ]
    }
   ],
   "source": [
    "auc_knn = roc_auc_score(cross_Y_test-1, predictions_knn[:,2])\n",
    "print(auc_knn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ##### ---------------------2.The proccess for subset of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 21)\n"
     ]
    }
   ],
   "source": [
    "X_train_sub = X_train[:,:20] # first 20 features\n",
    "Y_train_sub = Y_train\n",
    "X_test_sub = X_test[:,:20] # first 20 features\n",
    "X_Y_train_sub = np.column_stack((X_train_sub,Y_train_sub))\n",
    "print(X_Y_train_sub.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### First:split sub-feature data into k-folds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 100, 21)\n"
     ]
    }
   ],
   "source": [
    "seed(1)\n",
    "fold_sub = 2\n",
    "splited_data_sub = np.array(cross_validation_split(X_Y_train_sub,fold_sub))\n",
    "print(splited_data_sub.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1..Train data with cross validation to calculate the avarage accuracy and choose the Best K and observe average accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.42, 4), (0.52, 0)]\n",
      "The average accuracy : 0.47\n",
      "The average k : 2.0\n"
     ]
    }
   ],
   "source": [
    "result_sub = []\n",
    "for i in range(fold_sub):\n",
    "    fold_X_train_sub = splited_data_sub[i,:,:-1]\n",
    "    fold_Y_train_sub = splited_data_sub[i,:,-1]\n",
    "    cross_fold_X_train_sub, cross_fold_X_test_sub, cross_fold_Y_train_sub, cross_fold_Y_test_sub = train_test_split(fold_X_train_sub,fold_Y_train_sub, test_size=0.5,random_state=1234)\n",
    "    ctrain = Counter(cross_fold_Y_train_sub.flatten())\n",
    "    \n",
    "    Kvals = np.arange(1,100,1)\n",
    "    accuracy = []\n",
    "\n",
    "    for k in Kvals:\n",
    "        correct = 0\n",
    "        for i,row in enumerate(cross_fold_Y_test_sub):\n",
    "            c = knn_classifier(cross_fold_X_train_sub,cross_fold_Y_train_sub,row,K=k)[\"predicted_class\"]\n",
    "            if c == cross_fold_Y_test_sub[i]:\n",
    "                correct += 1\n",
    "        accuracy.append(1.0*correct / (1.0*len(cross_fold_Y_test_sub)))\n",
    "    result_sub.append((max(accuracy),np.array(accuracy).argmax()))\n",
    "print(result_sub)\n",
    "temp = 0\n",
    "k = 0\n",
    "for (i,j) in result_sub:\n",
    "    temp += i\n",
    "    k += j\n",
    "print(\"The average accuracy :\",temp/len(result_sub))\n",
    "print(\"The average k :\",k/len(result_sub))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ##### ---------------------3.Compare the performance of KNN with whole features and subset of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The performance for the whole feature data using KNN sharing the average accuracy around 0.86 with k-fold cross validation,whereas the performance for subset of feature(20 features) data using KNN sharing the average accuracy around 0.47 using k-fold cross validation with same k folds,which indicate the for KNN classifier ,the accuracy might be higher for that classifier if we deploy more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
