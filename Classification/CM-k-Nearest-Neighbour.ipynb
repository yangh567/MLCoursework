{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week 7: KNN, Naive Bayes Classifier, and ROC/AUC analysis\n",
    "\n",
    "- #### Aims:\n",
    "    - ##### Implement a KNN classifier\n",
    "    - ##### Implement a Naive Bayes classifier\n",
    "    - ##### Compare the two classifiers with ROC and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, roc_auc_score \n",
    "from collections import Counter\n",
    "from random import seed\n",
    "from random import randrange\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import feature_selection\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1:  Implement a KNN classifier\n",
    "\n",
    "\n",
    "##### Task 1.1: Load classification data\n",
    "Download `trainx.csv` and `testx.csv` from Moodle. In trainx.csv, each row corresponds to an instance. The first two columns are the values for two features and the third is the class label. The same format is used in `testx.csv`. Load these datasets into python (numpy.loadtxt) and create an X matrix consisting of the first two columns and a t vector as the last one. Do the same for the test data so you have four objects: $\\mathbf{X}$, $\\mathbf{X}_{test}$, $\\mathbf{t}$ and $\\mathbf{t}_{test}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 113)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.loadtxt('X_train.csv', delimiter=',', skiprows=1)\n",
    "X_test = np.loadtxt('X_test.csv', delimiter=',', skiprows=1)\n",
    "Y_train = np.loadtxt('y_train.csv', delimiter=',', skiprows=1)[:,1][:,None]\n",
    "\n",
    "# Make an instance of the Model\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "feature_scaler = StandardScaler()\n",
    "X_train = feature_scaler.fit_transform(X_train)\n",
    "X_test = feature_scaler.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_Y_train = np.column_stack((X_train,Y_train))\n",
    "print(X_Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### writting the function to split data for cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 100, 113)\n"
     ]
    }
   ],
   "source": [
    "# Split a dataset into k folds\n",
    "def cross_validation_split(dataset, folds):\n",
    "    dataset_split = list()\n",
    "    dataset_copy = list(dataset)\n",
    "    fold_size = int(len(dataset) / folds)\n",
    "    for i in range(folds):\n",
    "        fold = list()\n",
    "        while len(fold) < fold_size:\n",
    "            index = randrange(len(dataset_copy))\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        dataset_split.append(fold)\n",
    "    return dataset_split\n",
    " \n",
    "# test cross validation split\n",
    "seed(1)\n",
    "fold = 2\n",
    "splited_data = np.array(cross_validation_split(X_Y_train,fold))\n",
    "print(splited_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 1.2: Write a KNN function for a single test example (a row)\n",
    "Implement a KNN function that takes a single test example and a value of K and returns a classification. Your function should find the K closest (see below) training points to the test point and return the majority class\n",
    "amongst these training points.\n",
    "\n",
    "If your training data is in a numpy array with 100 rows and 2 columns, then the distance between a test point and the ith row is given by:\n",
    "\n",
    "`sq_diff = (test_row - trainx[i,:])**2\n",
    "dist = np.sqrt(sq_diff.sum())`\n",
    "\n",
    "where test_row is a row of $\\mathbf{X}_{test}$.\n",
    "The first line creates a new vector which holds the squared difference of the two pairs of values. The second line takes the sum of these differences and then takes the square root. This is computing the Euclidean distance. Other distance metrics could also be used.\n",
    "\n",
    "The `zip`, `sorted` and `numpy`'s `unique` can be helpful for finding the nearest neighbours.\n",
    "\n",
    "Make sure your function returns both the predicted class and predicted score. For KNN, the score can be the percentage of votes for each class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_classifier(trainX, traint, test_data, K):\n",
    "    distances = np.sqrt( ((trainX - test_data)**2).sum(axis=1)) # computing distances from the testing data to all training data\n",
    "    dc = zip(distances, traint) \n",
    "    dc = sorted(dc, key = lambda x: x[0]) # sort distance \n",
    "    selected_neighbor = np.asarray(dc[:K]) # select K number of neareast neighbours\n",
    "    classes, counts = np.unique(selected_neighbor[:,1], return_counts=True)\n",
    "    prediction = {}\n",
    "    prediction[\"predicted_class\"] = classes[counts.argmax()]\n",
    "    \n",
    "    if ( len(classes) == 1 and classes[counts.argmax()] == 2.0):\n",
    "        prediction[\"predicted_score\"] = np.hstack( (1.0- (1.0*counts/sum(counts)), 1.0*counts/sum(counts) ) )\n",
    "    elif ( len(classes) == 1 and classes[counts.argmax()] == 1.0):\n",
    "        prediction[\"predicted_score\"] = np.hstack( ( 1.0*counts/sum(counts), 1.0- (1.0*counts/sum(counts)) ) )\n",
    "    else:\n",
    "        prediction[\"predicted_score\"] = 1.0*counts/sum(counts)\n",
    "    return(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 1.3: Test with cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.82, 7), (0.9, 0)]\n",
      "The average accuracy : 0.86\n",
      "The average k : 3.5\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for i in range(fold):\n",
    "    fold_X_train = splited_data[i,:,:112]\n",
    "    fold_Y_train = splited_data[i,:,112:]\n",
    "    cross_fold_X_train, cross_fold_X_test, cross_fold_Y_train, cross_fold_Y_test = train_test_split(fold_X_train,fold_Y_train, test_size=0.5,random_state=1234)\n",
    "    ctrain = Counter(cross_fold_Y_train.flatten())\n",
    "    \n",
    "    Kvals = np.arange(1,100,1)\n",
    "    accuracy = []\n",
    "\n",
    "    for k in Kvals:\n",
    "        correct = 0\n",
    "        for i,row in enumerate(cross_fold_X_test):\n",
    "            c = knn_classifier(cross_fold_X_train,cross_fold_Y_train,row,K=k)[\"predicted_class\"]\n",
    "            if c == cross_fold_Y_test[i]:\n",
    "                correct += 1\n",
    "        accuracy.append(1.0*correct / (1.0*len(cross_fold_X_test)))\n",
    "    results.append((max(accuracy),np.array(accuracy).argmax()))\n",
    "print(results)\n",
    "temp = 0\n",
    "k = 0\n",
    "for (i,j) in results:\n",
    "    temp += i\n",
    "    k += j\n",
    "print(\"The average accuracy :\",temp/len(results))\n",
    "print(\"The average k :\",k/len(results))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 1.4: make prediction for KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction = []\n",
    "for i in range(len(X_test)):\n",
    "    c = knn_classifier(X_train,Y_train,X_test[i,:],K=4)\n",
    "    y_prediction.append(c[\"predicted_class\"])\n",
    "y_prediction = np.array(y_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.   2.]\n",
      " [  1.   2.]\n",
      " [  2.   2.]\n",
      " ...\n",
      " [795.   1.]\n",
      " [796.   2.]\n",
      " [797.   2.]]\n"
     ]
    }
   ],
   "source": [
    "test_header = \"Id,EpiOrStroma\"\n",
    "n_points = X_test.shape[0]\n",
    "y_pred_pp = np.ones((n_points, 2))\n",
    "y_pred_pp[:, 0] = range(n_points)\n",
    "y_pred_pp[:, 1] = y_prediction[:,0]\n",
    "print(y_pred_pp)\n",
    "\n",
    "np.savetxt('my_submission_k_nearest_neighbour_cl.csv', y_pred_pp, fmt='%d', delimiter=\",\",header=test_header, comments=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 3.2: Make predictions with KNN (K = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_knn = np.zeros((50, 3))\n",
    "for j,tx in enumerate(cross_fold_X_test):\n",
    "    knn_results = knn_classifier(cross_fold_X_train, cross_fold_Y_train, tx, K = 4)\n",
    "    predictions_knn[j, 0] = knn_results['predicted_class']\n",
    "    predictions_knn[j, 1:] = knn_results['predicted_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 3.3: test the last cross_fold_X_test 's ROC curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Sensitivity or True Positive Rate')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr_knn, tpr_knn, th_knn = roc_curve(cross_fold_Y_test-1, predictions_knn[:,2])\n",
    "plt.plot(fpr_knn, tpr_knn, \"r\")\n",
    "plt.xlabel(\"1-Specificity  or False Positive Rate\")\n",
    "plt.ylabel(\"Sensitivity or True Positive Rate\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task 3.4:  Compute the AUC for the two classifier \n",
    "\n",
    "AUCs range between 0.5 and 1. Higher AUC indicates better classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9342948717948719\n"
     ]
    }
   ],
   "source": [
    "auc_knn = roc_auc_score(cross_fold_Y_test-1, predictions_knn[:,2])\n",
    "print(auc_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
